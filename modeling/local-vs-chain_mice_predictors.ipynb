{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models vs Model Chains (using MICE only on the predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the scores of the local models and the two model chains (where we propagate the true values of the predictions) for the case where we impute the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from chaining import Chain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_and_categorical_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Stratify categorical variables\n",
    "    for col in df.select_dtypes(include=['category']):\n",
    "        counts = df[col].value_counts(normalize=True)\n",
    "        for category in counts.index:\n",
    "            idx = df[col] == category\n",
    "            cv[idx] = cv[idx].fillna(np.random.choice(np.where(idx)[0], size=int(counts[category] * N_FOLDS), replace=False))\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_paths = [\n",
    "    'C:/Users/lenne/OneDrive/Documenten/Master of Statistics and Data Science/2023-2024/Master thesis/Thesis_Sofia_Lennert/new_data',\n",
    "    'C:/Users/anaso/Desktop/SOFIA MENDES/KU Leuven/Master Thesis/Thesis_Sofia_Lennert/new_data'\n",
    "]\n",
    "\n",
    "# Define file names\n",
    "file = 'merged_data.csv'\n",
    "\n",
    "# Find full paths to the CSV files\n",
    "path = next((f'{path}/{file}' for path in possible_paths if os.path.exists(f'{path}/{file}')), None)\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Bin the number of relapses into 0, 1, 2, 3 and 4+ \n",
    "def bin_column(value):\n",
    "    if value in [0, 1, 2, 3]:\n",
    "        return str(value)\n",
    "    else:\n",
    "        return '4+'\n",
    "data['NRELAP'] = data['NRELAP'].apply(bin_column)\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of target variables, and listed already in the chain order \n",
    "variables = ['KFSS_M-2y', 'KFSS_P-2y', 'EDSS-2y', 'T25FW-2y', 'NHPT-2y', 'P_R36-SF12-after', 'M_R36-SF12-after', \n",
    "             'SES_after', 'SLEC_after', 'KFSS_M-after_2y', 'KFSS_P-after_2y', 'EDSS-after_2y', 'NRELAP', 'CESEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract targets\n",
    "targets = data[variables]\n",
    "\n",
    "# Choice of input variables\n",
    "columns_to_keep = ['AGE', 'SEX', 'RACE', 'CONTINENT', 'MHDIAGN', 'CARDIO', 'URINARY', 'MUSCKELET', 'FATIGUE', \n",
    "                    'NHPT-before', 'PASAT_2s-before', 'PASAT_3s-before', 'SDMT-before', 'T25FW-before', 'SLEC_before','SES_before',\n",
    "                    'BDI-before', 'EDSS-before', 'KFSS_M-before', 'KFSS_P-before', 'M_R36-SF12-before',\n",
    "                \t'P_R36-SF12-before', 'R36-SF12-before_Ind', 'T-before','P-before','N-before']\n",
    "\n",
    "features = data[columns_to_keep]\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding for categorical and binary input variables\n",
    "object_columns = features.select_dtypes(include=['object'])\n",
    "features = pd.get_dummies(features, columns=object_columns.columns, dtype=int)\n",
    "#features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFSS_M-2y           float64\n",
       "KFSS_P-2y           float64\n",
       "EDSS-2y             float64\n",
       "T25FW-2y            float64\n",
       "NHPT-2y             float64\n",
       "P_R36-SF12-after    float64\n",
       "M_R36-SF12-after    float64\n",
       "SES_after           float64\n",
       "SLEC_after          float64\n",
       "KFSS_M-after_2y     float64\n",
       "KFSS_P-after_2y     float64\n",
       "EDSS-after_2y       float64\n",
       "NRELAP               object\n",
       "CESEV                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MICE (only on the predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Impute the features\n",
    "featuresM=features.copy()\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "imputed_values = imputer.fit_transform(featuresM)\n",
    "\n",
    "featuresM = pd.DataFrame(imputed_values, columns=featuresM.columns)\n",
    "#featuresM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of values for each numerical column:\n",
      "AGE                     65.055452\n",
      "NHPT-before            288.400000\n",
      "PASAT_2s-before         67.470180\n",
      "PASAT_3s-before         58.500000\n",
      "SDMT-before            599.509092\n",
      "T25FW-before           131.400000\n",
      "SLEC_before            676.739216\n",
      "SES_before               1.195100\n",
      "BDI-before               0.856293\n",
      "EDSS-before              6.500000\n",
      "KFSS_M-before            0.685185\n",
      "KFSS_P-before            0.750000\n",
      "M_R36-SF12-before        0.885714\n",
      "P_R36-SF12-before        0.769231\n",
      "R36-SF12-before_Ind      1.292154\n",
      "T-before                 1.004456\n",
      "P-before                 1.001466\n",
      "N-before                 1.009040\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the range for the numerical columns\n",
    "ranges = featuresM.apply(lambda x: x.max() - x.min())\n",
    "filtered_ranges = ranges[ranges != 1]\n",
    "\n",
    "print(\"Range of values for each numerical column:\")\n",
    "print(filtered_ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state for reproducibility\n",
    "random_state = 42\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV Fold\n",
       "4.0    510\n",
       "3.0    502\n",
       "0.0    500\n",
       "1.0    495\n",
       "2.0    458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate CV folds\n",
    "cv=missingness_and_categorical_stratified_cv(targets, N_FOLDS, random_state)\n",
    "cv = cv.to_frame(name=\"CV Fold\")\n",
    "\n",
    "featuresM_cv = pd.merge(featuresM, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "targets_cv = pd.merge(targets, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "\n",
    "featuresM_cv['CV Fold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = featuresM_cv[featuresM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = featuresM_cv[featuresM_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=False, #RUN LOCAL MODELS\n",
    "    )\n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)): \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st index: fold, 2nd index: outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (local):\n",
      "KFSS_M-2y: 0.801993 (± 0.025655)\n",
      "KFSS_P-2y: 0.749011 (± 0.038689)\n",
      "EDSS-2y: 0.884741 (± 0.010655)\n",
      "T25FW-2y: 0.721337 (± 0.080981)\n",
      "NHPT-2y: 0.468891 (± 0.141997)\n",
      "P_R36-SF12-after: 0.691447 (± 0.018421)\n",
      "M_R36-SF12-after: 0.564273 (± 0.030070)\n",
      "SES_after: 0.677333 (± 0.061041)\n",
      "SLEC_after: 0.662808 (± 0.048430)\n",
      "KFSS_M-after_2y: 0.656742 (± 0.052867)\n",
      "KFSS_P-after_2y: 0.514128 (± 0.067097)\n",
      "EDSS-after_2y: 0.762599 (± 0.019359)\n",
      "NRELAP: 0.639202 (± 0.007540)\n",
      "CESEV: 0.502255 (± 0.031509)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)]\n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "print(\"Scores for each outcome (local):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = featuresM_cv[featuresM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = featuresM_cv[featuresM_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"pred\", \n",
    "    )\n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)): \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - predicted values):\n",
      "KFSS_M-2y: 0.801993 (± 0.025655)\n",
      "KFSS_P-2y: 0.747191 (± 0.039567)\n",
      "EDSS-2y: 0.881290 (± 0.007774)\n",
      "T25FW-2y: 0.740085 (± 0.079319)\n",
      "NHPT-2y: 0.503423 (± 0.134221)\n",
      "P_R36-SF12-after: 0.695016 (± 0.017991)\n",
      "M_R36-SF12-after: 0.547300 (± 0.045922)\n",
      "SES_after: 0.683117 (± 0.053856)\n",
      "SLEC_after: 0.658831 (± 0.039445)\n",
      "KFSS_M-after_2y: 0.642361 (± 0.052312)\n",
      "KFSS_P-after_2y: 0.497837 (± 0.047400)\n",
      "EDSS-after_2y: 0.751028 (± 0.020558)\n",
      "NRELAP: 0.638318 (± 0.009705)\n",
      "CESEV: 0.498230 (± 0.033473)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "print(\"Scores for each outcome (chain - predicted values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = featuresM_cv[featuresM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = featuresM_cv[featuresM_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"true\", \n",
    "    )\n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)): \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - true values):\n",
      "KFSS_M-2y: 0.801993 (± 0.025655)\n",
      "KFSS_P-2y: 0.747342 (± 0.036192)\n",
      "EDSS-2y: 0.883853 (± 0.007862)\n",
      "T25FW-2y: 0.726783 (± 0.085063)\n",
      "NHPT-2y: 0.531867 (± 0.121893)\n",
      "P_R36-SF12-after: 0.699690 (± 0.016158)\n",
      "M_R36-SF12-after: 0.551385 (± 0.043258)\n",
      "SES_after: 0.680335 (± 0.059968)\n",
      "SLEC_after: 0.657440 (± 0.043905)\n",
      "KFSS_M-after_2y: 0.651941 (± 0.051768)\n",
      "KFSS_P-after_2y: 0.502402 (± 0.031067)\n",
      "EDSS-after_2y: 0.763588 (± 0.028184)\n",
      "NRELAP: 0.644841 (± 0.016794)\n",
      "CESEV: 0.556423 (± 0.046957)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "print(\"Scores for each outcome (chain - true values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
