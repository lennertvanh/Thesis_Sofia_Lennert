{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models vs Model Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the scores of the local models and the two model chains (where we propagate the true values of the predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from chaining import Chain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_and_categorical_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Stratify categorical variables\n",
    "    for col in df.select_dtypes(include=['category']):\n",
    "        counts = df[col].value_counts(normalize=True)\n",
    "        for category in counts.index:\n",
    "            idx = df[col] == category\n",
    "            cv[idx] = cv[idx].fillna(np.random.choice(np.where(idx)[0], size=int(counts[category] * N_FOLDS), replace=False))\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert path to data file here\n",
    "possible_paths = [\n",
    "    'C:/Users/lenne/OneDrive/Documenten/Master of Statistics and Data Science/2023-2024/Master thesis/Thesis_Sofia_Lennert/new_data',\n",
    "    'C:/Users/anaso/Desktop/SOFIA MENDES/KU Leuven/Master Thesis/Thesis_Sofia_Lennert/new_data'\n",
    "]\n",
    "\n",
    "# File name\n",
    "file = 'merged_data.csv'\n",
    "\n",
    "# Find full paths to the CSV files\n",
    "path = next((f'{path}/{file}' for path in possible_paths if os.path.exists(f'{path}/{file}')), None)\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Bin the number of relapses into 0, 1, 2, 3 and 4+ \n",
    "def bin_column(value):\n",
    "    if value in [0, 1, 2, 3]:\n",
    "        return str(value)\n",
    "    else:\n",
    "        return '4+'\n",
    "data['NRELAP'] = data['NRELAP'].apply(bin_column)\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of target variables, and listed already in the chain order \n",
    "variables = ['KFSS_M-2y', 'KFSS_P-2y', 'EDSS-2y', 'T25FW-2y', 'NHPT-2y', 'P_R36-SF12-after', 'M_R36-SF12-after', \n",
    "             'SES_after', 'SLEC_after', 'KFSS_M-after_2y', 'KFSS_P-after_2y', 'EDSS-after_2y', 'NRELAP', 'CESEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract targets\n",
    "targets = data[variables]\n",
    "\n",
    "# Choice of input variables\n",
    "columns_to_keep = ['AGE', 'SEX', 'RACE', 'CONTINENT', 'MHDIAGN', 'CARDIO', 'URINARY', 'MUSCKELET', 'FATIGUE', \n",
    "                    'NHPT-before', 'PASAT_2s-before', 'PASAT_3s-before', 'SDMT-before', 'T25FW-before', 'SLEC_before','SES_before',\n",
    "                    'BDI-before', 'EDSS-before', 'KFSS_M-before', 'KFSS_P-before', 'M_R36-SF12-before',\n",
    "                \t'P_R36-SF12-before', 'R36-SF12-before_Ind', 'T-before','P-before','N-before']\n",
    "\n",
    "features = data[columns_to_keep]\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding for categorical and binary input variables\n",
    "object_columns = features.select_dtypes(include=['object'])\n",
    "features = pd.get_dummies(features, columns=object_columns.columns, dtype=int)\n",
    "#features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFSS_M-2y           float64\n",
       "KFSS_P-2y           float64\n",
       "EDSS-2y             float64\n",
       "T25FW-2y            float64\n",
       "NHPT-2y             float64\n",
       "P_R36-SF12-after    float64\n",
       "M_R36-SF12-after    float64\n",
       "SES_after           float64\n",
       "SLEC_after          float64\n",
       "KFSS_M-after_2y     float64\n",
       "KFSS_P-after_2y     float64\n",
       "EDSS-after_2y       float64\n",
       "NRELAP               object\n",
       "CESEV                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state for reproducibility\n",
    "random_state = 42\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV Fold\n",
       "4.0    510\n",
       "3.0    502\n",
       "0.0    500\n",
       "1.0    495\n",
       "2.0    458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate CV folds\n",
    "cv=missingness_and_categorical_stratified_cv(targets, N_FOLDS, random_state)\n",
    "cv = cv.to_frame(name=\"CV Fold\")\n",
    "\n",
    "features_cv = pd.merge(features, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "targets_cv = pd.merge(targets, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "\n",
    "targets_cv['CV Fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaso\\AppData\\Local\\Temp\\ipykernel_40924\\1893073231.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  missing_percentages = grouped.apply(lambda x: x.isna().mean() * 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KFSS_M-2y</th>\n",
       "      <th>KFSS_P-2y</th>\n",
       "      <th>EDSS-2y</th>\n",
       "      <th>T25FW-2y</th>\n",
       "      <th>NHPT-2y</th>\n",
       "      <th>P_R36-SF12-after</th>\n",
       "      <th>M_R36-SF12-after</th>\n",
       "      <th>SES_after</th>\n",
       "      <th>SLEC_after</th>\n",
       "      <th>KFSS_M-after_2y</th>\n",
       "      <th>KFSS_P-after_2y</th>\n",
       "      <th>EDSS-after_2y</th>\n",
       "      <th>NRELAP</th>\n",
       "      <th>CESEV</th>\n",
       "      <th>CV Fold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>44.200000</td>\n",
       "      <td>44.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>30.800000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>72.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>48.888889</td>\n",
       "      <td>48.888889</td>\n",
       "      <td>36.363636</td>\n",
       "      <td>33.737374</td>\n",
       "      <td>36.767677</td>\n",
       "      <td>39.191919</td>\n",
       "      <td>39.191919</td>\n",
       "      <td>68.888889</td>\n",
       "      <td>68.888889</td>\n",
       "      <td>80.606061</td>\n",
       "      <td>80.606061</td>\n",
       "      <td>76.161616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>44.541485</td>\n",
       "      <td>44.541485</td>\n",
       "      <td>34.061135</td>\n",
       "      <td>31.877729</td>\n",
       "      <td>34.061135</td>\n",
       "      <td>37.991266</td>\n",
       "      <td>37.991266</td>\n",
       "      <td>64.410480</td>\n",
       "      <td>64.410480</td>\n",
       "      <td>78.820961</td>\n",
       "      <td>78.820961</td>\n",
       "      <td>74.890830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.515284</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>48.406375</td>\n",
       "      <td>48.406375</td>\n",
       "      <td>34.262948</td>\n",
       "      <td>31.872510</td>\n",
       "      <td>34.262948</td>\n",
       "      <td>37.250996</td>\n",
       "      <td>37.250996</td>\n",
       "      <td>71.314741</td>\n",
       "      <td>71.314741</td>\n",
       "      <td>75.896414</td>\n",
       "      <td>75.896414</td>\n",
       "      <td>70.517928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.749004</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>48.039216</td>\n",
       "      <td>48.039216</td>\n",
       "      <td>34.901961</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>35.098039</td>\n",
       "      <td>38.823529</td>\n",
       "      <td>38.823529</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.196078</td>\n",
       "      <td>80.196078</td>\n",
       "      <td>74.509804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.568627</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         KFSS_M-2y  KFSS_P-2y    EDSS-2y   T25FW-2y    NHPT-2y  \\\n",
       "CV Fold                                                          \n",
       "0.0      44.200000  44.200000  33.000000  30.800000  33.200000   \n",
       "1.0      48.888889  48.888889  36.363636  33.737374  36.767677   \n",
       "2.0      44.541485  44.541485  34.061135  31.877729  34.061135   \n",
       "3.0      48.406375  48.406375  34.262948  31.872510  34.262948   \n",
       "4.0      48.039216  48.039216  34.901961  33.333333  35.098039   \n",
       "\n",
       "         P_R36-SF12-after  M_R36-SF12-after  SES_after  SLEC_after  \\\n",
       "CV Fold                                                              \n",
       "0.0             36.600000         36.600000  66.000000   66.000000   \n",
       "1.0             39.191919         39.191919  68.888889   68.888889   \n",
       "2.0             37.991266         37.991266  64.410480   64.410480   \n",
       "3.0             37.250996         37.250996  71.314741   71.314741   \n",
       "4.0             38.823529         38.823529  70.000000   70.000000   \n",
       "\n",
       "         KFSS_M-after_2y  KFSS_P-after_2y  EDSS-after_2y  NRELAP      CESEV  \\\n",
       "CV Fold                                                                       \n",
       "0.0            77.000000        77.000000      72.800000     0.0  64.000000   \n",
       "1.0            80.606061        80.606061      76.161616     0.0  62.222222   \n",
       "2.0            78.820961        78.820961      74.890830     0.0  58.515284   \n",
       "3.0            75.896414        75.896414      70.517928     0.0  62.749004   \n",
       "4.0            80.196078        80.196078      74.509804     0.0  61.568627   \n",
       "\n",
       "         CV Fold  \n",
       "CV Fold           \n",
       "0.0          0.0  \n",
       "1.0          0.0  \n",
       "2.0          0.0  \n",
       "3.0          0.0  \n",
       "4.0          0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by CV fold value\n",
    "grouped = targets_cv.groupby('CV Fold')\n",
    "\n",
    "# Calculate the percentage of missing values for each variable in each CV fold\n",
    "missing_percentages = grouped.apply(lambda x: x.isna().mean() * 100)\n",
    "missing_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anaso\\AppData\\Local\\Temp\\ipykernel_40924\\672282790.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cat_percentage_counts = grouped.apply(lambda x: x[['NRELAP', 'CESEV']].apply(lambda y: y.value_counts(normalize=True) * 100))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NRELAP</th>\n",
       "      <th>CESEV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">0.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>67.400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>17.600000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>7.400000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4+</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MILD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODERATE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEVERE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>65.454545</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>18.585859</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>9.090909</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>3.636364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4+</th>\n",
       "      <td>3.232323</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MILD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25.668449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODERATE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.427807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEVERE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.903743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>62.663755</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20.960699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>10.917031</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.401747</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4+</th>\n",
       "      <td>3.056769</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MILD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>22.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODERATE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>60.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEVERE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>65.139442</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20.517928</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>8.565737</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2.788845</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4+</th>\n",
       "      <td>2.988048</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MILD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>29.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODERATE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>53.475936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEVERE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17.112299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">4.0</th>\n",
       "      <th>0.0</th>\n",
       "      <td>66.078431</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>20.784314</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>7.058824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>3.921569</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4+</th>\n",
       "      <td>2.156863</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MILD</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODERATE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEVERE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     NRELAP      CESEV\n",
       "CV Fold                               \n",
       "0.0     0.0       67.400000        NaN\n",
       "        1.0       17.600000        NaN\n",
       "        2.0        7.400000        NaN\n",
       "        3.0        3.800000        NaN\n",
       "        4+         3.800000        NaN\n",
       "        MILD            NaN  20.000000\n",
       "        MODERATE        NaN  60.000000\n",
       "        SEVERE          NaN  20.000000\n",
       "1.0     0.0       65.454545        NaN\n",
       "        1.0       18.585859        NaN\n",
       "        2.0        9.090909        NaN\n",
       "        3.0        3.636364        NaN\n",
       "        4+         3.232323        NaN\n",
       "        MILD            NaN  25.668449\n",
       "        MODERATE        NaN  60.427807\n",
       "        SEVERE          NaN  13.903743\n",
       "2.0     0.0       62.663755        NaN\n",
       "        1.0       20.960699        NaN\n",
       "        2.0       10.917031        NaN\n",
       "        3.0        2.401747        NaN\n",
       "        4+         3.056769        NaN\n",
       "        MILD            NaN  22.631579\n",
       "        MODERATE        NaN  60.526316\n",
       "        SEVERE          NaN  16.842105\n",
       "3.0     0.0       65.139442        NaN\n",
       "        1.0       20.517928        NaN\n",
       "        2.0        8.565737        NaN\n",
       "        3.0        2.788845        NaN\n",
       "        4+         2.988048        NaN\n",
       "        MILD            NaN  29.411765\n",
       "        MODERATE        NaN  53.475936\n",
       "        SEVERE          NaN  17.112299\n",
       "4.0     0.0       66.078431        NaN\n",
       "        1.0       20.784314        NaN\n",
       "        2.0        7.058824        NaN\n",
       "        3.0        3.921569        NaN\n",
       "        4+         2.156863        NaN\n",
       "        MILD            NaN  28.571429\n",
       "        MODERATE        NaN  50.000000\n",
       "        SEVERE          NaN  21.428571"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the relative percentage count of each level of NRELAP and CESEV within each CV fold\n",
    "cat_percentage_counts = grouped.apply(lambda x: x[['NRELAP', 'CESEV']].apply(lambda y: y.value_counts(normalize=True) * 100))\n",
    "cat_percentage_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = features_cv[features_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = features_cv[features_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=False, #RUN LOCAL MODELS\n",
    "    )\n",
    "    \n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)\n",
    "# y_test_cv[fold][outcome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st index: fold, 2nd index: outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (local):\n",
      "KFSS_M-2y: 0.806110 (± 0.024257)\n",
      "KFSS_P-2y: 0.747655 (± 0.035666)\n",
      "EDSS-2y: 0.881740 (± 0.012522)\n",
      "T25FW-2y: 0.723295 (± 0.082169)\n",
      "NHPT-2y: 0.487602 (± 0.100730)\n",
      "P_R36-SF12-after: 0.692193 (± 0.018844)\n",
      "M_R36-SF12-after: 0.566317 (± 0.025900)\n",
      "SES_after: 0.673104 (± 0.061261)\n",
      "SLEC_after: 0.661404 (± 0.048492)\n",
      "KFSS_M-after_2y: 0.652697 (± 0.051669)\n",
      "KFSS_P-after_2y: 0.508382 (± 0.075025)\n",
      "EDSS-after_2y: 0.756476 (± 0.023314)\n",
      "NRELAP: 0.637156 (± 0.010758)\n",
      "CESEV: 0.498147 (± 0.035706)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables:\n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "\n",
    "print(\"Scores for each outcome (local):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = features_cv[features_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = features_cv[features_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"pred\", \n",
    "    )\n",
    "    \n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - predicted values):\n",
      "KFSS_M-2y: 0.806110 (± 0.024257)\n",
      "KFSS_P-2y: 0.748826 (± 0.038452)\n",
      "EDSS-2y: 0.878399 (± 0.009057)\n",
      "T25FW-2y: 0.739289 (± 0.068823)\n",
      "NHPT-2y: 0.543487 (± 0.106313)\n",
      "P_R36-SF12-after: 0.693806 (± 0.021025)\n",
      "M_R36-SF12-after: 0.539594 (± 0.043098)\n",
      "SES_after: 0.675966 (± 0.048457)\n",
      "SLEC_after: 0.657846 (± 0.050603)\n",
      "KFSS_M-after_2y: 0.644624 (± 0.051360)\n",
      "KFSS_P-after_2y: 0.496987 (± 0.079715)\n",
      "EDSS-after_2y: 0.747596 (± 0.027036)\n",
      "NRELAP: 0.637414 (± 0.015700)\n",
      "CESEV: 0.490859 (± 0.038634)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "\n",
    "print(\"Scores for each outcome (chain - predicted values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = features_cv[features_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = features_cv[features_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"true\",\n",
    "    )\n",
    "    \n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - true values):\n",
      "KFSS_M-2y: 0.806110 (± 0.024257)\n",
      "KFSS_P-2y: 0.748199 (± 0.035516)\n",
      "EDSS-2y: 0.882074 (± 0.009358)\n",
      "T25FW-2y: 0.743260 (± 0.081836)\n",
      "NHPT-2y: 0.547253 (± 0.112405)\n",
      "P_R36-SF12-after: 0.701295 (± 0.017075)\n",
      "M_R36-SF12-after: 0.548614 (± 0.041483)\n",
      "SES_after: 0.677078 (± 0.061710)\n",
      "SLEC_after: 0.657925 (± 0.043438)\n",
      "KFSS_M-after_2y: 0.657765 (± 0.057367)\n",
      "KFSS_P-after_2y: 0.507064 (± 0.051130)\n",
      "EDSS-after_2y: 0.758362 (± 0.027480)\n",
      "NRELAP: 0.634280 (± 0.020465)\n",
      "CESEV: 0.563588 (± 0.042535)\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store scores\n",
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "\n",
    "print(\"Scores for each outcome (chain - true values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
