{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Relative Brier Score - Ensemble of 50 Model Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the Average Relative Brier scores of an ensemble of 50 Model Chains where we propagate the true target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as mse, brier_score_loss\n",
    "from chaining import Chain\n",
    "import os\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutations_with_order(variables, pairs_or_groups, num_permutations, constrained_elements=None, shuffle_at_end=None, random_state=None):\n",
    "    random.seed(random_state)\n",
    "    permutations_list = [list(variables)]  # Add the original order only once as a list of strings\n",
    "    \n",
    "    while len(permutations_list) < num_permutations + 1: # +1 because the original order is counted too\n",
    "        perm = list(random.sample(variables, len(variables)))\n",
    "        valid = True\n",
    "        \n",
    "        for pair_or_group in pairs_or_groups:\n",
    "            idxs = [perm.index(var) for var in pair_or_group]\n",
    "            if sorted(idxs) != idxs:\n",
    "                valid = False\n",
    "                break\n",
    "        \n",
    "        if valid:\n",
    "            if constrained_elements:\n",
    "                # Check if all constrained elements are present in the first positions of the permutation\n",
    "                if all(elem in perm[:len(constrained_elements)] for elem in constrained_elements):\n",
    "                    permutations_list.append(perm)\n",
    "    \n",
    "    # Shuffle the positions of variables specified to be shuffled at the end\n",
    "    if shuffle_at_end:\n",
    "        for idx, perm in enumerate(permutations_list[1:], start=1):  # Start from index 1 because original order shouldn't be shuffled\n",
    "            for variable in shuffle_at_end:\n",
    "                if variable in perm:\n",
    "                    perm.remove(variable)\n",
    "                    perm.insert(random.randint(0, len(perm)), variable)\n",
    "    \n",
    "    return permutations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_and_categorical_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Stratify categorical variables\n",
    "    for col in df.select_dtypes(include=['category']):\n",
    "        counts = df[col].value_counts(normalize=True)\n",
    "        for category in counts.index:\n",
    "            idx = df[col] == category\n",
    "            cv[idx] = cv[idx].fillna(np.random.choice(np.where(idx)[0], size=int(counts[category] * N_FOLDS), replace=False))\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_mean_squared_error(true, pred, train):\n",
    "    num = mse(true, pred)\n",
    "    mean_value = np.mean(train)\n",
    "    mean = np.full_like(true, mean_value)\n",
    "    den = mse(true, mean)\n",
    "    nmse_loss = num/den\n",
    "    \n",
    "    return nmse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reorder columns of dataframes\n",
    "def reorder_columns(dataframes):\n",
    "    column_order = dataframes[0].columns\n",
    "    reordered_dataframes = [df[column_order] for df in dataframes]\n",
    "    return reordered_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average dataframes\n",
    "def average_dataframes(dataframes):\n",
    "    concatenated_df = pd.concat(dataframes)\n",
    "    # Group by index and calculate the mode for object columns and mean for other types\n",
    "    averaged_df = concatenated_df.groupby(concatenated_df.index).agg(lambda x: x.mode()[0] if x.dtype == 'O' else x.mean())\n",
    "    return averaged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_paths = [\n",
    "    'C:/Users/lenne/OneDrive/Documenten/Master of Statistics and Data Science/2023-2024/Master thesis/Thesis_Sofia_Lennert/new_data',\n",
    "    'C:/Users/anaso/Desktop/SOFIA MENDES/KU Leuven/Master Thesis/Thesis_Sofia_Lennert/new_data'\n",
    "]\n",
    "\n",
    "# File name\n",
    "file = 'merged_data.csv'\n",
    "\n",
    "# Find full paths to the CSV files\n",
    "path = next((f'{path}/{file}' for path in possible_paths if os.path.exists(f'{path}/{file}')), None)\n",
    "\n",
    "# Resulting DataFrame will have aggregated data from all four datasets based on the specific_column\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "def bin_column(value):\n",
    "    if value in [0, 1, 2, 3]:\n",
    "        return str(value)\n",
    "    else:\n",
    "        return '4+'\n",
    "data['NRELAP'] = data['NRELAP'].apply(bin_column)\n",
    "\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of target variables, and listed already in the chain order \n",
    "variables = ['KFSS_M-2y', 'KFSS_P-2y', 'EDSS-2y', 'T25FW-2y', 'NHPT-2y', 'P_R36-SF12-after', 'M_R36-SF12-after', \n",
    "             'SES_after', 'SLEC_after', 'KFSS_M-after_2y', 'KFSS_P-after_2y', 'EDSS-after_2y', 'NRELAP', 'CESEV']\n",
    "\n",
    "# Choice of input variables\n",
    "columns_to_keep = ['AGE', 'SEX', 'RACE', 'CONTINENT', 'MHDIAGN', 'CARDIO', 'URINARY', 'MUSCKELET', 'FATIGUE', \n",
    "                    'NHPT-before', 'PASAT_2s-before', 'PASAT_3s-before', 'SDMT-before', 'T25FW-before', 'SLEC_before','SES_before',\n",
    "                    'BDI-before', 'EDSS-before', 'KFSS_M-before', 'KFSS_P-before', 'M_R36-SF12-before',\n",
    "                \t'P_R36-SF12-before', 'R36-SF12-before_Ind', 'T-before','P-before','N-before']\n",
    "\n",
    "features = data[columns_to_keep]\n",
    "#features\n",
    "\n",
    "targets = data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding for categorical and binary input variables\n",
    "object_columns = features.select_dtypes(include=['object'])\n",
    "features = pd.get_dummies(features, columns=object_columns.columns, dtype=int)\n",
    "#features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation 0: KFSS_M-2y, KFSS_P-2y, EDSS-2y, T25FW-2y, NHPT-2y, P_R36-SF12-after, M_R36-SF12-after, SES_after, SLEC_after, KFSS_M-after_2y, KFSS_P-after_2y, EDSS-after_2y, NRELAP, CESEV\n",
      "Permutation 1: T25FW-2y, KFSS_M-2y, NHPT-2y, KFSS_P-2y, EDSS-2y, NRELAP, KFSS_M-after_2y, SLEC_after, M_R36-SF12-after, CESEV, P_R36-SF12-after, KFSS_P-after_2y, EDSS-after_2y, SES_after\n",
      "Permutation 2: NHPT-2y, NRELAP, KFSS_P-2y, KFSS_M-2y, T25FW-2y, CESEV, EDSS-2y, M_R36-SF12-after, SES_after, SLEC_after, KFSS_P-after_2y, P_R36-SF12-after, KFSS_M-after_2y, EDSS-after_2y\n",
      "Permutation 3: NHPT-2y, KFSS_P-2y, KFSS_M-2y, T25FW-2y, EDSS-2y, KFSS_P-after_2y, M_R36-SF12-after, CESEV, P_R36-SF12-after, SES_after, SLEC_after, KFSS_M-after_2y, EDSS-after_2y, NRELAP\n",
      "Permutation 4: KFSS_P-2y, KFSS_M-2y, NHPT-2y, T25FW-2y, EDSS-2y, NRELAP, KFSS_M-after_2y, P_R36-SF12-after, CESEV, KFSS_P-after_2y, SES_after, SLEC_after, EDSS-after_2y, M_R36-SF12-after\n",
      "Permutation 5: T25FW-2y, KFSS_M-2y, KFSS_P-2y, EDSS-2y, NHPT-2y, KFSS_P-after_2y, SLEC_after, CESEV, NRELAP, SES_after, KFSS_M-after_2y, P_R36-SF12-after, EDSS-after_2y, M_R36-SF12-after\n",
      "Permutation 6: KFSS_P-2y, CESEV, NRELAP, NHPT-2y, T25FW-2y, KFSS_M-2y, EDSS-2y, KFSS_M-after_2y, KFSS_P-after_2y, P_R36-SF12-after, SLEC_after, SES_after, EDSS-after_2y, M_R36-SF12-after\n",
      "Permutation 7: CESEV, KFSS_M-2y, T25FW-2y, NHPT-2y, NRELAP, KFSS_P-2y, EDSS-2y, KFSS_M-after_2y, SES_after, KFSS_P-after_2y, SLEC_after, M_R36-SF12-after, EDSS-after_2y, P_R36-SF12-after\n",
      "Permutation 8: KFSS_P-2y, T25FW-2y, KFSS_M-2y, NHPT-2y, NRELAP, EDSS-2y, SES_after, M_R36-SF12-after, KFSS_P-after_2y, KFSS_M-after_2y, SLEC_after, EDSS-after_2y, P_R36-SF12-after, CESEV\n",
      "Permutation 9: CESEV, KFSS_P-2y, NRELAP, T25FW-2y, KFSS_M-2y, NHPT-2y, EDSS-2y, KFSS_P-after_2y, SES_after, SLEC_after, M_R36-SF12-after, KFSS_M-after_2y, P_R36-SF12-after, EDSS-after_2y\n",
      "Permutation 10: KFSS_M-2y, KFSS_P-2y, EDSS-2y, NHPT-2y, NRELAP, T25FW-2y, KFSS_M-after_2y, SES_after, P_R36-SF12-after, M_R36-SF12-after, CESEV, SLEC_after, KFSS_P-after_2y, EDSS-after_2y\n",
      "Permutation 11: NRELAP, KFSS_P-2y, KFSS_M-2y, T25FW-2y, NHPT-2y, EDSS-2y, KFSS_P-after_2y, CESEV, M_R36-SF12-after, KFSS_M-after_2y, SLEC_after, P_R36-SF12-after, SES_after, EDSS-after_2y\n",
      "Permutation 12: NHPT-2y, KFSS_P-2y, T25FW-2y, KFSS_M-2y, EDSS-2y, M_R36-SF12-after, P_R36-SF12-after, KFSS_M-after_2y, CESEV, KFSS_P-after_2y, SLEC_after, EDSS-after_2y, SES_after, NRELAP\n",
      "Permutation 13: KFSS_M-2y, T25FW-2y, KFSS_P-2y, EDSS-2y, NHPT-2y, CESEV, P_R36-SF12-after, KFSS_M-after_2y, SES_after, NRELAP, M_R36-SF12-after, KFSS_P-after_2y, SLEC_after, EDSS-after_2y\n",
      "Permutation 14: KFSS_P-2y, T25FW-2y, NHPT-2y, KFSS_M-2y, EDSS-2y, SLEC_after, KFSS_M-after_2y, CESEV, NRELAP, SES_after, M_R36-SF12-after, KFSS_P-after_2y, P_R36-SF12-after, EDSS-after_2y\n",
      "Permutation 15: NHPT-2y, T25FW-2y, KFSS_M-2y, KFSS_P-2y, EDSS-2y, SES_after, KFSS_P-after_2y, P_R36-SF12-after, KFSS_M-after_2y, EDSS-after_2y, CESEV, SLEC_after, NRELAP, M_R36-SF12-after\n",
      "Permutation 16: KFSS_P-2y, T25FW-2y, KFSS_M-2y, EDSS-2y, NHPT-2y, CESEV, SES_after, KFSS_M-after_2y, M_R36-SF12-after, KFSS_P-after_2y, SLEC_after, NRELAP, EDSS-after_2y, P_R36-SF12-after\n",
      "Permutation 17: KFSS_M-2y, T25FW-2y, KFSS_P-2y, NRELAP, NHPT-2y, EDSS-2y, KFSS_P-after_2y, KFSS_M-after_2y, SLEC_after, M_R36-SF12-after, CESEV, SES_after, EDSS-after_2y, P_R36-SF12-after\n",
      "Permutation 18: KFSS_P-2y, KFSS_M-2y, CESEV, EDSS-2y, NHPT-2y, NRELAP, T25FW-2y, SES_after, P_R36-SF12-after, SLEC_after, KFSS_P-after_2y, KFSS_M-after_2y, EDSS-after_2y, M_R36-SF12-after\n",
      "Permutation 19: NHPT-2y, KFSS_P-2y, NRELAP, KFSS_M-2y, T25FW-2y, EDSS-2y, KFSS_P-after_2y, SLEC_after, KFSS_M-after_2y, M_R36-SF12-after, P_R36-SF12-after, SES_after, EDSS-after_2y, CESEV\n",
      "Permutation 20: KFSS_M-2y, KFSS_P-2y, EDSS-2y, T25FW-2y, NHPT-2y, NRELAP, SES_after, KFSS_P-after_2y, SLEC_after, KFSS_M-after_2y, EDSS-after_2y, CESEV, M_R36-SF12-after, P_R36-SF12-after\n",
      "Permutation 21: NHPT-2y, KFSS_P-2y, KFSS_M-2y, T25FW-2y, EDSS-2y, CESEV, SLEC_after, SES_after, NRELAP, KFSS_P-after_2y, KFSS_M-after_2y, P_R36-SF12-after, EDSS-after_2y, M_R36-SF12-after\n",
      "Permutation 22: NHPT-2y, T25FW-2y, KFSS_M-2y, KFSS_P-2y, NRELAP, EDSS-2y, KFSS_P-after_2y, SES_after, SLEC_after, KFSS_M-after_2y, CESEV, P_R36-SF12-after, EDSS-after_2y, M_R36-SF12-after\n",
      "Permutation 23: CESEV, NRELAP, KFSS_P-2y, NHPT-2y, KFSS_M-2y, T25FW-2y, EDSS-2y, P_R36-SF12-after, KFSS_P-after_2y, KFSS_M-after_2y, SLEC_after, EDSS-after_2y, SES_after, M_R36-SF12-after\n",
      "Permutation 24: KFSS_M-2y, NHPT-2y, T25FW-2y, KFSS_P-2y, EDSS-2y, KFSS_P-after_2y, SES_after, NRELAP, CESEV, KFSS_M-after_2y, SLEC_after, EDSS-after_2y, M_R36-SF12-after, P_R36-SF12-after\n",
      "Permutation 25: KFSS_P-2y, NHPT-2y, KFSS_M-2y, EDSS-2y, CESEV, T25FW-2y, KFSS_M-after_2y, M_R36-SF12-after, SES_after, SLEC_after, NRELAP, P_R36-SF12-after, KFSS_P-after_2y, EDSS-after_2y\n",
      "Permutation 26: T25FW-2y, KFSS_P-2y, KFSS_M-2y, NHPT-2y, EDSS-2y, KFSS_M-after_2y, KFSS_P-after_2y, M_R36-SF12-after, EDSS-after_2y, NRELAP, SES_after, P_R36-SF12-after, SLEC_after, CESEV\n",
      "Permutation 27: NHPT-2y, KFSS_M-2y, KFSS_P-2y, NRELAP, EDSS-2y, T25FW-2y, KFSS_P-after_2y, P_R36-SF12-after, M_R36-SF12-after, SLEC_after, KFSS_M-after_2y, EDSS-after_2y, CESEV, SES_after\n",
      "Permutation 28: T25FW-2y, KFSS_M-2y, KFSS_P-2y, NRELAP, NHPT-2y, EDSS-2y, KFSS_M-after_2y, KFSS_P-after_2y, M_R36-SF12-after, EDSS-after_2y, P_R36-SF12-after, SLEC_after, CESEV, SES_after\n",
      "Permutation 29: KFSS_M-2y, KFSS_P-2y, T25FW-2y, EDSS-2y, NHPT-2y, KFSS_P-after_2y, SLEC_after, M_R36-SF12-after, P_R36-SF12-after, SES_after, KFSS_M-after_2y, CESEV, NRELAP, EDSS-after_2y\n",
      "Permutation 30: KFSS_P-2y, T25FW-2y, KFSS_M-2y, NHPT-2y, EDSS-2y, KFSS_M-after_2y, KFSS_P-after_2y, M_R36-SF12-after, P_R36-SF12-after, SLEC_after, EDSS-after_2y, CESEV, SES_after, NRELAP\n",
      "Permutation 31: NHPT-2y, KFSS_M-2y, CESEV, T25FW-2y, KFSS_P-2y, EDSS-2y, P_R36-SF12-after, NRELAP, SLEC_after, KFSS_M-after_2y, SES_after, KFSS_P-after_2y, EDSS-after_2y, M_R36-SF12-after\n",
      "Permutation 32: NHPT-2y, KFSS_M-2y, KFSS_P-2y, T25FW-2y, NRELAP, EDSS-2y, KFSS_M-after_2y, M_R36-SF12-after, SLEC_after, CESEV, KFSS_P-after_2y, EDSS-after_2y, SES_after, P_R36-SF12-after\n",
      "Permutation 33: KFSS_P-2y, NHPT-2y, KFSS_M-2y, NRELAP, CESEV, EDSS-2y, T25FW-2y, SLEC_after, M_R36-SF12-after, SES_after, KFSS_P-after_2y, KFSS_M-after_2y, EDSS-after_2y, P_R36-SF12-after\n",
      "Permutation 34: CESEV, NHPT-2y, KFSS_M-2y, KFSS_P-2y, T25FW-2y, EDSS-2y, NRELAP, SES_after, P_R36-SF12-after, M_R36-SF12-after, KFSS_P-after_2y, KFSS_M-after_2y, EDSS-after_2y, SLEC_after\n",
      "Permutation 35: KFSS_P-2y, KFSS_M-2y, EDSS-2y, T25FW-2y, NHPT-2y, P_R36-SF12-after, SES_after, CESEV, M_R36-SF12-after, NRELAP, KFSS_P-after_2y, KFSS_M-after_2y, EDSS-after_2y, SLEC_after\n",
      "Permutation 36: KFSS_M-2y, T25FW-2y, KFSS_P-2y, EDSS-2y, NHPT-2y, CESEV, SLEC_after, KFSS_P-after_2y, NRELAP, KFSS_M-after_2y, EDSS-after_2y, M_R36-SF12-after, SES_after, P_R36-SF12-after\n",
      "Permutation 37: NHPT-2y, NRELAP, T25FW-2y, KFSS_M-2y, CESEV, KFSS_P-2y, EDSS-2y, SES_after, KFSS_P-after_2y, P_R36-SF12-after, SLEC_after, M_R36-SF12-after, KFSS_M-after_2y, EDSS-after_2y\n",
      "Permutation 38: NRELAP, T25FW-2y, KFSS_M-2y, KFSS_P-2y, EDSS-2y, NHPT-2y, KFSS_P-after_2y, M_R36-SF12-after, KFSS_M-after_2y, P_R36-SF12-after, EDSS-after_2y, CESEV, SES_after, SLEC_after\n",
      "Permutation 39: T25FW-2y, KFSS_P-2y, NHPT-2y, KFSS_M-2y, EDSS-2y, SES_after, M_R36-SF12-after, P_R36-SF12-after, KFSS_P-after_2y, SLEC_after, KFSS_M-after_2y, CESEV, NRELAP, EDSS-after_2y\n",
      "Permutation 40: KFSS_M-2y, KFSS_P-2y, NHPT-2y, T25FW-2y, EDSS-2y, KFSS_M-after_2y, KFSS_P-after_2y, CESEV, NRELAP, M_R36-SF12-after, P_R36-SF12-after, EDSS-after_2y, SLEC_after, SES_after\n",
      "Permutation 41: KFSS_M-2y, KFSS_P-2y, NHPT-2y, EDSS-2y, T25FW-2y, P_R36-SF12-after, KFSS_P-after_2y, SES_after, CESEV, KFSS_M-after_2y, M_R36-SF12-after, SLEC_after, NRELAP, EDSS-after_2y\n",
      "Permutation 42: KFSS_M-2y, KFSS_P-2y, EDSS-2y, NHPT-2y, T25FW-2y, SLEC_after, KFSS_P-after_2y, M_R36-SF12-after, P_R36-SF12-after, KFSS_M-after_2y, NRELAP, EDSS-after_2y, CESEV, SES_after\n",
      "Permutation 43: KFSS_M-2y, KFSS_P-2y, T25FW-2y, EDSS-2y, NHPT-2y, SES_after, CESEV, KFSS_M-after_2y, NRELAP, SLEC_after, P_R36-SF12-after, KFSS_P-after_2y, M_R36-SF12-after, EDSS-after_2y\n",
      "Permutation 44: T25FW-2y, KFSS_P-2y, NHPT-2y, KFSS_M-2y, EDSS-2y, M_R36-SF12-after, CESEV, KFSS_P-after_2y, KFSS_M-after_2y, NRELAP, P_R36-SF12-after, SES_after, EDSS-after_2y, SLEC_after\n",
      "Permutation 45: NRELAP, KFSS_M-2y, T25FW-2y, KFSS_P-2y, EDSS-2y, CESEV, NHPT-2y, KFSS_M-after_2y, M_R36-SF12-after, KFSS_P-after_2y, SLEC_after, P_R36-SF12-after, SES_after, EDSS-after_2y\n",
      "Permutation 46: NHPT-2y, KFSS_M-2y, T25FW-2y, KFSS_P-2y, EDSS-2y, P_R36-SF12-after, KFSS_M-after_2y, NRELAP, SLEC_after, CESEV, M_R36-SF12-after, KFSS_P-after_2y, SES_after, EDSS-after_2y\n",
      "Permutation 47: T25FW-2y, CESEV, KFSS_P-2y, NHPT-2y, KFSS_M-2y, EDSS-2y, KFSS_P-after_2y, M_R36-SF12-after, KFSS_M-after_2y, P_R36-SF12-after, EDSS-after_2y, SES_after, SLEC_after, NRELAP\n",
      "Permutation 48: CESEV, KFSS_M-2y, KFSS_P-2y, T25FW-2y, NHPT-2y, NRELAP, EDSS-2y, KFSS_M-after_2y, KFSS_P-after_2y, SES_after, M_R36-SF12-after, EDSS-after_2y, P_R36-SF12-after, SLEC_after\n",
      "Permutation 49: CESEV, T25FW-2y, KFSS_P-2y, KFSS_M-2y, EDSS-2y, NHPT-2y, NRELAP, P_R36-SF12-after, KFSS_M-after_2y, KFSS_P-after_2y, SLEC_after, M_R36-SF12-after, SES_after, EDSS-after_2y\n"
     ]
    }
   ],
   "source": [
    "# Generate 50 permutations of the target variables: the chain orders for the different chains in the ensemble\n",
    "pairs_or_groups = [['KFSS_M-2y', 'EDSS-2y'], ['KFSS_P-2y', 'EDSS-2y'], ['KFSS_M-after_2y', 'EDSS-after_2y'], ['KFSS_P-after_2y', 'EDSS-after_2y']]  # Specify the pairs or groups\n",
    "order_constraint = ['KFSS_M-2y', 'KFSS_P-2y', 'EDSS-2y', 'T25FW-2y', 'NHPT-2y']\n",
    "shuffle_at_end = ['NRELAP', 'CESEV']  # Specify variables to be shuffled at the end\n",
    "num_permutations = 49  # Specify how many random permutations you want\n",
    "random_state = 42\n",
    "\n",
    "random_permutations = generate_permutations_with_order(variables, pairs_or_groups, num_permutations, order_constraint, shuffle_at_end, random_state)\n",
    "\n",
    "# Print the original order followed by all the random permutations\n",
    "for idx, perm in enumerate(random_permutations, start=0):\n",
    "    print(f\"Permutation {idx}: {', '.join(perm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_targets = random_permutations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state for reproducibility\n",
    "random_state = 42\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate CV folds\n",
    "cv=missingness_and_categorical_stratified_cv(targets, N_FOLDS, random_state)\n",
    "cv = cv.to_frame(name=\"CV Fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain with *true* values propagated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n",
      "Permutation done\n"
     ]
    }
   ],
   "source": [
    "y_pred_chains = []\n",
    "y_pred_prob_list_chain = []\n",
    "y_test_list = [[] for _ in range(N_FOLDS)]  # Initialize y_test_list with empty lists for each fold index\n",
    "y_train_list = [[] for _ in range(N_FOLDS)] \n",
    "yi_test_dummies_list = [[] for _ in range(N_FOLDS)]\n",
    "yi_train_dummies_list = [[] for _ in range(N_FOLDS)]\n",
    "\n",
    "\n",
    "# Iterate over each chain ordering\n",
    "for ordered_targets_chain in random_permutations:\n",
    "    y_pred_list = []  # List to store predictions for this chain\n",
    "    y_pred_prob_list = []\n",
    "    \n",
    "    features_cv = pd.merge(features, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "    targets_cv = pd.merge(data[ordered_targets_chain], pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "\n",
    "    # Fit and predict for each fold for this chain\n",
    "    for i in range(0, N_FOLDS): \n",
    "        Xi_train = features_cv[features_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "        Xi_test = features_cv[features_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "        yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "        yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "\n",
    "        # One hot encode categorical targets of test set to be able to compute brier score\n",
    "        subset_yi_test = yi_test.select_dtypes(include=['object'])\n",
    "        yi_test_dummies = pd.get_dummies(subset_yi_test, columns=subset_yi_test.columns, dtype=int)\n",
    "        subset_yi_train = yi_train.select_dtypes(include=['object'])\n",
    "        yi_train_dummies = pd.get_dummies(subset_yi_train, columns=subset_yi_train.columns, dtype=int)\n",
    "\n",
    "\n",
    "        chain = Chain(\n",
    "            model_reg=RandomForestRegressor(random_state=random_state),\n",
    "            model_clf=RandomForestClassifier(random_state=random_state),\n",
    "            propagate=\"true\",\n",
    "        )\n",
    "\n",
    "\n",
    "        chain.fit(Xi_train, yi_train, target_types=None)\n",
    "        y_pred = chain.predict(Xi_test)\n",
    "        y_pred_prob = chain.predict_proba(Xi_test)\n",
    "        y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "        y_pred_prob_list.append(y_pred_prob)\n",
    "    \n",
    "        # Append yi_test to the corresponding fold index in y_test_list\n",
    "        y_test_list[i].append(yi_test)  \n",
    "        y_train_list[i].append(yi_train)\n",
    "        yi_test_dummies_list[i].append(yi_test_dummies)\n",
    "        yi_train_dummies_list[i].append(yi_train_dummies)\n",
    "\n",
    "    y_pred_chains.append(y_pred_list)\n",
    "    y_pred_prob_list_chain.append(y_pred_prob_list)\n",
    "    print(\"Permutation done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dfs_chain = []\n",
    "\n",
    "for y_pred_prob_list in y_pred_prob_list_chain:\n",
    "    concatenated_dfs_fold = []\n",
    "    # Iterate over each pair of arrays\n",
    "    for j, fold in enumerate(y_pred_prob_list):\n",
    "        dfs = []\n",
    "        len_array = 0\n",
    "        \n",
    "        for i, array in enumerate(fold):\n",
    "            # Convert array to DataFrame\n",
    "            col = yi_test_dummies_list[j][0].columns[len_array:len_array+len(array[0])]\n",
    "            df = pd.DataFrame(array, columns=col, index=yi_test_dummies_list[j][0].index)\n",
    "            dfs.append(df)\n",
    "            len_array += len(array[0])\n",
    "        \n",
    "        # Concatenate DataFrames\n",
    "        concatenated_df = pd.concat(dfs, axis=1)\n",
    "        concatenated_dfs_fold.append(concatenated_df)\n",
    "\n",
    "    concatenated_dfs_chain.append(concatenated_dfs_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_list_cat = list(zip(*concatenated_dfs_chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element of transposed_list is a tuple containing dataframes from the same position in each inner list\n",
    "reorganized_list_cat = [list(df_tuple) for df_tuple in transposed_list_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_reorganized_list_cat = [reorder_columns(dataframes) for dataframes in reorganized_list_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_dataframes_list_cat = [average_dataframes(dataframes) for dataframes in reordered_reorganized_list_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_list_all = list(zip(*y_pred_chains))\n",
    "\n",
    "reorganized_list_all = [list(df_tuple) for df_tuple in transposed_list_all]\n",
    "\n",
    "reordered_reorganized_list_all = [reorder_columns(dataframes) for dataframes in reorganized_list_all]\n",
    "\n",
    "averaged_dataframes_list_all = [average_dataframes(dataframes) for dataframes in reordered_reorganized_list_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_test_list = list(zip(*y_test_list))\n",
    "\n",
    "reorganized_test_list = [list(df_tuple) for df_tuple in transposed_test_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_train_list = list(zip(*y_train_list))\n",
    "\n",
    "reorganized_train_list = [list(df_tuple) for df_tuple in transposed_train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_pred_list = averaged_dataframes_list_all.copy()\n",
    "y_test_list = reorganized_test_list[0]\n",
    "\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  # 5\n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  # or (1, 5)\n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorganized_train_list_first=reorganized_train_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - true values):\n",
      "KFSS_M-2y: 0.19 (± 0.02)\n",
      "KFSS_P-2y: 0.25 (± 0.03)\n",
      "EDSS-2y: 0.12 (± 0.01)\n",
      "T25FW-2y: 0.27 (± 0.09)\n",
      "NHPT-2y: 0.46 (± 0.11)\n",
      "P_R36-SF12-after: 0.30 (± 0.01)\n",
      "M_R36-SF12-after: 0.43 (± 0.03)\n",
      "SES_after: 0.31 (± 0.05)\n",
      "SLEC_after: 0.35 (± 0.04)\n",
      "KFSS_M-after_2y: 0.33 (± 0.05)\n",
      "KFSS_P-after_2y: 0.48 (± 0.05)\n",
      "EDSS-after_2y: 0.23 (± 0.02)\n"
     ]
    }
   ],
   "source": [
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Check if the target variable is numerical or categorical\n",
    "    if y_test_cv[0][variables.index(variable_name)].dtype.kind in 'bifc':\n",
    "        # Compute scores for the variable across all folds\n",
    "        for fold_index in range(len(y_test_cv)):\n",
    "            y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "            y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "            y_train = reorganized_train_list_first[fold_index][variable_name]\n",
    "\n",
    "            score = normalized_mean_squared_error(y_test, y_pred, y_train)\n",
    "            variable_scores.append(score)\n",
    "        \n",
    "        # Compute the average score for the variable across all folds\n",
    "        variable_avg_score = np.mean(variable_scores)\n",
    "        \n",
    "        # Compute the standard deviation for the variable across all folds\n",
    "        variable_std_score = np.std(variable_scores)\n",
    "        \n",
    "        # Append the tuple with three elements to the scores_with_std list\n",
    "        scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "num_normalized_brier=[]\n",
    "num_std_brier=[]\n",
    "# Print the scores with average and standard deviation along with variable names\n",
    "print(\"Scores for each outcome (chain - true values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.2f} (± {std_score:.2f})\")\n",
    "    num_normalized_brier.append(avg_score)\n",
    "    num_std_brier.append(std_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi_train_dummies_avg = []\n",
    "i=0\n",
    "\n",
    "for yi_train_dummies_fold in yi_train_dummies_list:\n",
    "    # Calculate the percentage of 1s in each column\n",
    "    yi_test_dummies_avg_fold=[]\n",
    "\n",
    "    for yi_train_dummies_chain in yi_train_dummies_fold:\n",
    "\n",
    "        percentages = yi_train_dummies_chain.sum() / len(yi_train_dummies_chain)\n",
    "\n",
    "        yi_train_dummies_avg_chain = pd.DataFrame(0, index=yi_test_dummies_list[i][0].index, columns=yi_train_dummies_chain.columns)\n",
    "\n",
    "        # Replace values in each column with the corresponding percentage\n",
    "        for col in yi_train_dummies_avg_chain.columns:\n",
    "            yi_train_dummies_avg_chain[col] = yi_train_dummies_avg_chain[col].apply(lambda x: percentages[col])\n",
    "        \n",
    "        yi_test_dummies_avg_fold.append(yi_train_dummies_avg_chain)\n",
    "\n",
    "    i += 1    \n",
    "    yi_train_dummies_avg.append(yi_test_dummies_avg_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_dummy_avg_list = list(zip(*yi_train_dummies_avg))\n",
    "\n",
    "reorganized_dummy_avg_list = [list(df_tuple) for df_tuple in transposed_dummy_avg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_dummy_list = list(zip(*yi_test_dummies_list))\n",
    "\n",
    "reorganized_dummy_list = [list(df_tuple) for df_tuple in transposed_dummy_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorganized_dummy_avg_list_first=reorganized_dummy_avg_list[0]\n",
    "reorganized_dummy_list_first=reorganized_dummy_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Brier scores for each categorical variable:\n",
      "NRELAP: 1.43 \n",
      "CESEV: 1.02 \n"
     ]
    }
   ],
   "source": [
    "scores_with_std = []\n",
    "variables_cat = reorganized_dummy_list_first[0].columns\n",
    "avg_brier_score = []\n",
    "avg_baseline_score = []\n",
    "cat_normalized_brier=[]\n",
    "\n",
    "# Create a dictionary to store the scores for variables with the same letters before the '_'\n",
    "brier_scores_dict = {}\n",
    "baseline_scores_dict = {}\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for level_name in variables_cat: \n",
    "    variable_scores = []\n",
    "    brier_scores = []\n",
    "    baseline_scores = []\n",
    "    \n",
    "    # Compute scores for the variable across all folds\n",
    "    for fold_index in range(len(yi_test_dummies_list)):\n",
    "        y_test = reorganized_dummy_list_first[fold_index][level_name] \n",
    "        y_prob = averaged_dataframes_list_cat[fold_index][level_name] \n",
    "        y_prob_avg = reorganized_dummy_avg_list_first[fold_index][level_name] \n",
    "        \n",
    "        # Compute the Brier score\n",
    "        brier_score = brier_score_loss(y_test, y_prob)\n",
    "        N_brier_score = brier_score#*N\n",
    "        brier_baseline = brier_score_loss(y_test, y_prob_avg)\n",
    "        N_brier_baseline = brier_baseline#*N\n",
    "\n",
    "        # Append the Brier score to the variable scores list\n",
    "        brier_scores.append(N_brier_score)\n",
    "        baseline_scores.append(N_brier_baseline)\n",
    "    \n",
    "    # Check if the variable name has letters before the '_'\n",
    "    prefix = level_name.split('_')[0]\n",
    "    \n",
    "    # Add the Brier scores to the dictionary based on the prefix\n",
    "    if prefix in brier_scores_dict:\n",
    "        brier_scores_dict[prefix].extend(brier_scores)\n",
    "    else:\n",
    "        brier_scores_dict[prefix] = brier_scores\n",
    "\n",
    "    if prefix in baseline_scores_dict:\n",
    "        baseline_scores_dict[prefix].extend(baseline_scores)\n",
    "    else:\n",
    "        baseline_scores_dict[prefix] = baseline_scores\n",
    "\n",
    "\n",
    "# Compute the average of Brier score for each prefix\n",
    "for prefix, scores in brier_scores_dict.items():\n",
    "    sum_score = np.sum(scores)\n",
    "    avg_brier_score.append((prefix, sum_score))\n",
    "\n",
    "for prefix, scores in baseline_scores_dict.items():\n",
    "    sum_score = np.sum(scores)\n",
    "    avg_baseline_score.append((prefix, sum_score))\n",
    "\n",
    "\n",
    "normalized_score_list = []\n",
    "for i in range(len(avg_brier_score)):\n",
    "    normalized_score = avg_brier_score[i][1]/avg_baseline_score[i][1]\n",
    "    cell = (avg_brier_score[i][0], normalized_score)\n",
    "    normalized_score_list.append(cell)\n",
    "\n",
    "\n",
    "print(\"Normalized Brier scores for each categorical variable:\")\n",
    "for prefix, avg_score in normalized_score_list:\n",
    "    print(f\"{prefix}: {avg_score:.2f} \")\n",
    "    cat_normalized_brier.append(avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19032649, 0.24630058, 0.11542459, 0.26710801, 0.46347487,\n",
       "       0.29537546, 0.42509999, 0.31049949, 0.34741666, 0.33224694,\n",
       "       0.47575159, 0.23498767, 1.43352778, 1.01737958])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate normalized brier scores for all variables (both numerical and categorical) \n",
    "combined_normalized_brier = np.concatenate((num_normalized_brier, cat_normalized_brier))\n",
    "combined_normalized_brier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized unifying score: 0.4396371224819819\n"
     ]
    }
   ],
   "source": [
    "# Compute the average relative Brier score\n",
    "average_normalized_brier = np.mean(combined_normalized_brier)\n",
    "print(\"Normalized unifying score:\", average_normalized_brier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
