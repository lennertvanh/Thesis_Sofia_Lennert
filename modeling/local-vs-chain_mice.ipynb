{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models vs Model Chains (using MICE on the whole dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook compares the scores of the local models and the two model chains (where we propagate the true values of the predictions) for the case where we impute the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from chaining import Chain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_and_categorical_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Stratify categorical variables\n",
    "    for col in df.select_dtypes(include=['category']):\n",
    "        counts = df[col].value_counts(normalize=True)\n",
    "        for category in counts.index:\n",
    "            idx = df[col] == category\n",
    "            cv[idx] = cv[idx].fillna(np.random.choice(np.where(idx)[0], size=int(counts[category] * N_FOLDS), replace=False))\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_paths = [\n",
    "    'C:/Users/lenne/OneDrive/Documenten/Master of Statistics and Data Science/2023-2024/Master thesis/Thesis_Sofia_Lennert/new_data',\n",
    "    'C:/Users/anaso/Desktop/SOFIA MENDES/KU Leuven/Master Thesis/Thesis_Sofia_Lennert/new_data'\n",
    "]\n",
    "\n",
    "# Define file names\n",
    "file = 'merged_data.csv'\n",
    "\n",
    "# Find full paths to the CSV files\n",
    "path = next((f'{path}/{file}' for path in possible_paths if os.path.exists(f'{path}/{file}')), None)\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Bin the number of relapses into 0, 1, 2, 3 and 4+ \n",
    "def bin_column(value):\n",
    "    if value in [0, 1, 2, 3]:\n",
    "        return str(value)\n",
    "    else:\n",
    "        return '4+'\n",
    "data['NRELAP'] = data['NRELAP'].apply(bin_column)\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of target variables, and listed already in the chain order \n",
    "variables = ['KFSS_M-2y', 'KFSS_P-2y', 'EDSS-2y', 'T25FW-2y', 'NHPT-2y', 'P_R36-SF12-after', 'M_R36-SF12-after', \n",
    "             'SES_after', 'SLEC_after', 'KFSS_M-after_2y', 'KFSS_P-after_2y', 'EDSS-after_2y', 'NRELAP', 'CESEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract targets\n",
    "targets = data[variables]\n",
    "\n",
    "# Choice of input variables\n",
    "columns_to_keep = ['AGE', 'SEX', 'RACE', 'CONTINENT', 'MHDIAGN', 'CARDIO', 'URINARY', 'MUSCKELET', 'FATIGUE', \n",
    "                    'NHPT-before', 'PASAT_2s-before', 'PASAT_3s-before', 'SDMT-before', 'T25FW-before', 'SLEC_before','SES_before',\n",
    "                    'BDI-before', 'EDSS-before', 'KFSS_M-before', 'KFSS_P-before', 'M_R36-SF12-before',\n",
    "                \t'P_R36-SF12-before', 'R36-SF12-before_Ind', 'T-before','P-before','N-before']\n",
    "\n",
    "features = data[columns_to_keep]\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding for categorical and binary input variables\n",
    "object_columns = features.select_dtypes(include=['object'])\n",
    "features = pd.get_dummies(features, columns=object_columns.columns, dtype=int)\n",
    "#features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFSS_M-2y           float64\n",
       "KFSS_P-2y           float64\n",
       "EDSS-2y             float64\n",
       "T25FW-2y            float64\n",
       "NHPT-2y             float64\n",
       "P_R36-SF12-after    float64\n",
       "M_R36-SF12-after    float64\n",
       "SES_after           float64\n",
       "SLEC_after          float64\n",
       "KFSS_M-after_2y     float64\n",
       "KFSS_P-after_2y     float64\n",
       "EDSS-after_2y       float64\n",
       "NRELAP               object\n",
       "CESEV                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MICE (on the entire dataset, using a two-step approach: first on X, then on [X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: impute the features\n",
    "featuresM=features.copy()\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "imputed_values = imputer.fit_transform(featuresM)\n",
    "\n",
    "featuresM = pd.DataFrame(imputed_values, columns=featuresM.columns)\n",
    "#featuresM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of values for each numerical column:\n",
      "AGE                     65.055452\n",
      "NHPT-before            288.400000\n",
      "PASAT_2s-before         67.470180\n",
      "PASAT_3s-before         58.500000\n",
      "SDMT-before            599.509092\n",
      "T25FW-before           131.400000\n",
      "SLEC_before            676.739216\n",
      "SES_before               1.195100\n",
      "BDI-before               0.856293\n",
      "EDSS-before              6.500000\n",
      "KFSS_M-before            0.685185\n",
      "KFSS_P-before            0.750000\n",
      "M_R36-SF12-before        0.885714\n",
      "P_R36-SF12-before        0.769231\n",
      "R36-SF12-before_Ind      1.292154\n",
      "T-before                 1.004456\n",
      "P-before                 1.001466\n",
      "N-before                 1.009040\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the range for the numerical columns\n",
    "ranges = featuresM.apply(lambda x: x.max() - x.min())\n",
    "filtered_ranges = ranges[ranges != 1]\n",
    "\n",
    "print(\"Range of values for each numerical column:\")\n",
    "print(filtered_ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate imputed features and targets\n",
    "model_data = pd.concat([featuresM, targets], axis=1)\n",
    "#model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenne\\anaconda3\\envs\\Thesis\\lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Impute the targets, based on model_data (= imputed features + targets)\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "cesev = le1.fit_transform(np.array(model_data['CESEV']))\n",
    "nrelap = le2.fit_transform(np.array(model_data['NRELAP']))\n",
    "\n",
    "model_data['CESEV'] = cesev\n",
    "model_data[\"CESEV\"] = model_data[\"CESEV\"].replace(3, np.nan)\n",
    "model_data['NRELAP'] = nrelap\n",
    "\n",
    "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "imputed_values = imputer.fit_transform(model_data)\n",
    "\n",
    "# Convert imputed values back to DataFrame\n",
    "encoded_data = pd.DataFrame(imputed_values, columns=model_data.columns)\n",
    "#encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_data[(encoded_data[\"CESEV\"] <= -0.5) | (encoded_data[\"CESEV\"] >= 2.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.loc[encoded_data['CESEV'] < -0.5, 'CESEV'] = 0\n",
    "\n",
    "cesev = np.array(encoded_data['CESEV']).round().astype(int)\n",
    "nrelap = np.array(encoded_data['NRELAP']).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_three(arr):\n",
    "    return np.where(arr == 3, 2, arr)\n",
    "\n",
    "cesev = replace_three(cesev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MODERATE', 'MILD', 'SEVERE'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data['CESEV'] = le1.inverse_transform(cesev)\n",
    "encoded_data['NRELAP'] = le2.inverse_transform(nrelap)\n",
    "encoded_data['CESEV'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetsM = encoded_data[targets.columns]\n",
    "#targetsM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of values for each numerical column:\n",
      "KFSS_M-2y             0.759259\n",
      "KFSS_P-2y             0.750000\n",
      "EDSS-2y               8.000000\n",
      "T25FW-2y            177.408688\n",
      "NHPT-2y             289.100000\n",
      "P_R36-SF12-after      0.750000\n",
      "M_R36-SF12-after      1.000000\n",
      "SES_after             1.885904\n",
      "SLEC_after          468.823191\n",
      "KFSS_M-after_2y       0.677183\n",
      "KFSS_P-after_2y       0.866265\n",
      "EDSS-after_2y        11.633106\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the range for the numerical targets (all except last 2)\n",
    "selected_columns = targetsM.iloc[:, :-2]\n",
    "ranges = selected_columns.apply(lambda x: x.max() - x.min())\n",
    "print(\"Range of values for each numerical column:\")\n",
    "print(ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state for reproducibility\n",
    "random_state = 42\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV Fold\n",
       "4.0    510\n",
       "3.0    502\n",
       "0.0    500\n",
       "1.0    495\n",
       "2.0    458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate CV folds\n",
    "cv=missingness_and_categorical_stratified_cv(targets, N_FOLDS, random_state)\n",
    "cv = cv.to_frame(name=\"CV Fold\")\n",
    "\n",
    "featuresM_cv = pd.merge(featuresM, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "targetsM_cv = pd.merge(targetsM, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "targets_cv = pd.merge(targets, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "\n",
    "featuresM_cv['CV Fold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = featuresM_cv[featuresM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = featuresM_cv[featuresM_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targetsM_cv[targetsM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=False, #RUN LOCAL MODELS\n",
    "    )\n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st index: fold, 2nd index: outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (local):\n",
      "KFSS_M-2y: 0.806122 (± 0.025077)\n",
      "KFSS_P-2y: 0.749510 (± 0.037254)\n",
      "EDSS-2y: 0.883254 (± 0.009163)\n",
      "T25FW-2y: 0.727442 (± 0.075562)\n",
      "NHPT-2y: 0.460561 (± 0.135160)\n",
      "P_R36-SF12-after: 0.689428 (± 0.020209)\n",
      "M_R36-SF12-after: 0.562895 (± 0.032070)\n",
      "SES_after: 0.694301 (± 0.059227)\n",
      "SLEC_after: 0.664256 (± 0.041770)\n",
      "KFSS_M-after_2y: 0.651214 (± 0.048865)\n",
      "KFSS_P-after_2y: 0.520523 (± 0.052801)\n",
      "EDSS-after_2y: 0.758917 (± 0.019338)\n",
      "NRELAP: 0.639202 (± 0.007540)\n",
      "CESEV: 0.517954 (± 0.040901)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store scores and std\n",
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Compute scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Compute the average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Compute the standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "# Print the scores with average and standard deviation along with variable names\n",
    "print(\"Scores for each outcome (local):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = featuresM_cv[featuresM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = featuresM_cv[featuresM_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targetsM_cv[targetsM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"pred\", \n",
    "    )\n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - predicted values):\n",
      "KFSS_M-2y: 0.806122 (± 0.025077)\n",
      "KFSS_P-2y: 0.746799 (± 0.038167)\n",
      "EDSS-2y: 0.879385 (± 0.008318)\n",
      "T25FW-2y: 0.735797 (± 0.071464)\n",
      "NHPT-2y: 0.562527 (± 0.121590)\n",
      "P_R36-SF12-after: 0.695134 (± 0.018180)\n",
      "M_R36-SF12-after: 0.547225 (± 0.041525)\n",
      "SES_after: 0.697053 (± 0.058774)\n",
      "SLEC_after: 0.664899 (± 0.040691)\n",
      "KFSS_M-after_2y: 0.653268 (± 0.042612)\n",
      "KFSS_P-after_2y: 0.502382 (± 0.082836)\n",
      "EDSS-after_2y: 0.740258 (± 0.020169)\n",
      "NRELAP: 0.637927 (± 0.007646)\n",
      "CESEV: 0.524368 (± 0.042350)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store scores and std\n",
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Compute scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Compute the average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Compute the standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "# Print the scores with average and standard deviation along with variable names\n",
    "print(\"Scores for each outcome (chain - predicted values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = featuresM_cv[featuresM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = featuresM_cv[featuresM_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targetsM_cv[targetsM_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"true\", \n",
    "    )\n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - true values):\n",
      "KFSS_M-2y: 0.806122 (± 0.025077)\n",
      "KFSS_P-2y: 0.748477 (± 0.035684)\n",
      "EDSS-2y: 0.879368 (± 0.007633)\n",
      "T25FW-2y: 0.739298 (± 0.076963)\n",
      "NHPT-2y: 0.540783 (± 0.102326)\n",
      "P_R36-SF12-after: 0.695870 (± 0.019222)\n",
      "M_R36-SF12-after: 0.553584 (± 0.040516)\n",
      "SES_after: 0.694352 (± 0.062094)\n",
      "SLEC_after: 0.667141 (± 0.040370)\n",
      "KFSS_M-after_2y: 0.661391 (± 0.045106)\n",
      "KFSS_P-after_2y: 0.516665 (± 0.050009)\n",
      "EDSS-after_2y: 0.746180 (± 0.016309)\n",
      "NRELAP: 0.587924 (± 0.017397)\n",
      "CESEV: 0.493292 (± 0.035835)\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store scores and std\n",
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Compute scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Compute the average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Compute the standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "# Print the scores with average and standard deviation along with variable names\n",
    "print(\"Scores for each outcome (chain - true values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
