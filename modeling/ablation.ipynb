{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the results of the local models and the two model chains (where we use the predictions or the true values at fit time) in the case where we exclude the pre-study measurements from the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from chaining import Chain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missingness_and_categorical_stratified_cv(df, N_FOLDS=5, random_state=None):\n",
    "    # Add seed for reproducibility of the predictions (to get the same scores each time we run the code)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # Initial complete-case test fold assignment\n",
    "    cv = pd.Series(np.nan, index=df.index)\n",
    "    i_cc = (df.isna().sum(axis=1) == 0) # Complete cases\n",
    "    cv.iloc[i_cc] = np.random.randint(low=0, high=N_FOLDS, size=i_cc.sum())\n",
    "\n",
    "    # Stratify categorical variables\n",
    "    for col in df.select_dtypes(include=['category']):\n",
    "        counts = df[col].value_counts(normalize=True)\n",
    "        for category in counts.index:\n",
    "            idx = df[col] == category\n",
    "            cv[idx] = cv[idx].fillna(np.random.choice(np.where(idx)[0], size=int(counts[category] * N_FOLDS), replace=False))\n",
    "\n",
    "    # Go over columns from most missing to least missing\n",
    "    for j in df.isna().sum().argsort()[::-1]:\n",
    "        # Instances i that are not assigned yet but for which df[i,j] is observed\n",
    "        i_tbf = (cv.isna()) & (~df.iloc[:,j].isna()) # to be filled\n",
    "        # Fill them randomly\n",
    "        cv.iloc[i_tbf] = np.random.randint(low=0, high=N_FOLDS, size=i_tbf.sum())\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert path to data file here\n",
    "possible_paths = [\n",
    "    'C:/Users/lenne/OneDrive/Documenten/Master of Statistics and Data Science/2023-2024/Master thesis/Thesis_Sofia_Lennert/new_data',\n",
    "    'C:/Users/anaso/Desktop/SOFIA MENDES/KU Leuven/Master Thesis/Thesis_Sofia_Lennert/new_data'\n",
    "]\n",
    "\n",
    "# File name\n",
    "file = 'merged_data.csv'\n",
    "\n",
    "# Find full paths to the CSV files\n",
    "path = next((f'{path}/{file}' for path in possible_paths if os.path.exists(f'{path}/{file}')), None)\n",
    "\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "# Bin the number of relapses into 0, 1, 2, 3 and 4+ \n",
    "def bin_column(value):\n",
    "    if value in [0, 1, 2, 3]:\n",
    "        return str(value)\n",
    "    else:\n",
    "        return '4+'\n",
    "data['NRELAP'] = data['NRELAP'].apply(bin_column)\n",
    "\n",
    "# Display all columns\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of target variables, and listed already in the chain order \n",
    "variables = ['KFSS_M-2y', 'KFSS_P-2y', 'EDSS-2y', 'T25FW-2y', 'NHPT-2y', 'P_R36-SF12-after', 'M_R36-SF12-after', \n",
    "             'SES_after', 'SLEC_after', 'KFSS_M-after_2y', 'KFSS_P-after_2y', 'EDSS-after_2y', 'NRELAP', 'CESEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract targets\n",
    "targets = data[variables]\n",
    "\n",
    "columns_to_keep = ['AGE', 'SEX', 'RACE', 'CONTINENT', 'MHDIAGN', 'CARDIO', 'URINARY', 'MUSCKELET', 'FATIGUE']\n",
    "                    #'PASAT_2s-before', 'PASAT_3s-before', 'SDMT-before', 'BDI-before', 'T-before','P-before','N-before']\n",
    "# removed: 'NHPT-before', 'T25FW-before', 'SLEC_before','SES_before','EDSS-before', 'KFSS_M-before', 'KFSS_P-before', 'M_R36-SF12-before', \n",
    "# 'P_R36-SF12-before', 'R36-SF12-before_Ind',\n",
    "\n",
    "features = data[columns_to_keep]\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding for categorical and binary input variables\n",
    "object_columns = features.select_dtypes(include=['object'])\n",
    "features = pd.get_dummies(features, columns=object_columns.columns, dtype=int)\n",
    "#features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFSS_M-2y           float64\n",
       "KFSS_P-2y           float64\n",
       "EDSS-2y             float64\n",
       "T25FW-2y            float64\n",
       "NHPT-2y             float64\n",
       "P_R36-SF12-after    float64\n",
       "M_R36-SF12-after    float64\n",
       "SES_after           float64\n",
       "SLEC_after          float64\n",
       "KFSS_M-after_2y     float64\n",
       "KFSS_P-after_2y     float64\n",
       "EDSS-after_2y       float64\n",
       "NRELAP               object\n",
       "CESEV                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state for reproducibility\n",
    "random_state = 42\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV Fold\n",
       "4.0    510\n",
       "3.0    502\n",
       "0.0    500\n",
       "1.0    495\n",
       "2.0    458\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate CV folds\n",
    "cv=missingness_and_categorical_stratified_cv(targets, N_FOLDS, random_state)\n",
    "cv = cv.to_frame(name=\"CV Fold\")\n",
    "\n",
    "features_cv = pd.merge(features, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "targets_cv = pd.merge(targets, pd.DataFrame(cv), left_index=True, right_index=True)\n",
    "\n",
    "features_cv['CV Fold'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = features_cv[features_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = features_cv[features_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=False, #RUN LOCAL MODELS\n",
    "    )\n",
    "    \n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)\n",
    "# y_test_cv[fold][outcome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st index: fold, 2nd index: outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (local):\n",
      "KFSS_M-2y: 0.279107 (± 0.075734)\n",
      "KFSS_P-2y: 0.121920 (± 0.113072)\n",
      "EDSS-2y: 0.479024 (± 0.026227)\n",
      "T25FW-2y: -0.233067 (± 0.223537)\n",
      "NHPT-2y: -0.345342 (± 0.344232)\n",
      "P_R36-SF12-after: 0.134056 (± 0.024751)\n",
      "M_R36-SF12-after: -0.090757 (± 0.034034)\n",
      "SES_after: -0.095536 (± 0.144894)\n",
      "SLEC_after: -0.132740 (± 0.081061)\n",
      "KFSS_M-after_2y: 0.233811 (± 0.064524)\n",
      "KFSS_P-after_2y: -0.117887 (± 0.267944)\n",
      "EDSS-after_2y: 0.392720 (± 0.059427)\n",
      "NRELAP: 0.589024 (± 0.014943)\n",
      "CESEV: 0.472243 (± 0.010192)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables:\n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "print(\"Scores for each outcome (local):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = features_cv[features_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = features_cv[features_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"pred\", \n",
    "    )\n",
    "    \n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows in y_test and y_pred where the variable in question is missing in y_test (since without it, it is not possible to calculate the score)\n",
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - predicted values):\n",
      "KFSS_M-2y: 0.279107 (± 0.075734)\n",
      "KFSS_P-2y: 0.169757 (± 0.093960)\n",
      "EDSS-2y: 0.459064 (± 0.034564)\n",
      "T25FW-2y: -0.168565 (± 0.123364)\n",
      "NHPT-2y: -0.175407 (± 0.291223)\n",
      "P_R36-SF12-after: 0.099579 (± 0.043239)\n",
      "M_R36-SF12-after: -0.159955 (± 0.074128)\n",
      "SES_after: -0.094218 (± 0.116886)\n",
      "SLEC_after: -0.174670 (± 0.104758)\n",
      "KFSS_M-after_2y: 0.186793 (± 0.049876)\n",
      "KFSS_P-after_2y: -0.167499 (± 0.194146)\n",
      "EDSS-after_2y: 0.309878 (± 0.070203)\n",
      "NRELAP: 0.615672 (± 0.008552)\n",
      "CESEV: 0.490634 (± 0.041260)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "print(\"Scores for each outcome (chain - predicted values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with evaluating on CV Fold 1\n",
      "Done with evaluating on CV Fold 2\n",
      "Done with evaluating on CV Fold 3\n",
      "Done with evaluating on CV Fold 4\n",
      "Done with evaluating on CV Fold 5\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for i in range(0, N_FOLDS): \n",
    "    Xi_train = features_cv[features_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    Xi_test = features_cv[features_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_train = targets_cv[targets_cv['CV Fold'] != i].drop([\"CV Fold\"], axis=1)\n",
    "    yi_test = targets_cv[targets_cv['CV Fold'] == i].drop([\"CV Fold\"], axis=1)\n",
    "    y_test_list.append(pd.DataFrame(yi_test, columns=yi_test.columns, index=yi_test.index))\n",
    "\n",
    "    chain = Chain(\n",
    "        model_reg=RandomForestRegressor(random_state=random_state),\n",
    "        model_clf=RandomForestClassifier(random_state=random_state),\n",
    "        propagate=\"true\",\n",
    "    )\n",
    "    chain.fit(Xi_train, yi_train, target_types=None) #[\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"reg\",\"clf\",\"clf\"]\n",
    "    y_pred = chain.predict(Xi_test)\n",
    "    y_pred_list.append(pd.DataFrame(y_pred, columns=yi_test.columns, index=yi_test.index))\n",
    "    print(\"Done with evaluating on CV Fold {}\".format(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cv = []\n",
    "y_pred_cv = []\n",
    "\n",
    "for j in range(len(y_test_list)):  \n",
    "    y_test_targ = []\n",
    "    y_pred_targ = []\n",
    "    nvar=y_test_list[0].shape[1]\n",
    "\n",
    "    for i in range(0, nvar):  \n",
    "        missing_rows_mask = y_test_list[j].iloc[:, i].isna()\n",
    "        y_test = y_test_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        y_pred = y_pred_list[j].iloc[:, i][~missing_rows_mask]\n",
    "        \n",
    "        y_test_targ.append(y_test)\n",
    "        y_pred_targ.append(y_pred)\n",
    "    \n",
    "    y_test_cv.append(y_test_targ)\n",
    "    y_pred_cv.append(y_pred_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each outcome (chain - true values):\n",
      "KFSS_M-2y: 0.279107 (± 0.075734)\n",
      "KFSS_P-2y: 0.184123 (± 0.084262)\n",
      "EDSS-2y: 0.500393 (± 0.023055)\n",
      "T25FW-2y: -0.001451 (± 0.067373)\n",
      "NHPT-2y: 0.060766 (± 0.049607)\n",
      "P_R36-SF12-after: 0.164702 (± 0.033727)\n",
      "M_R36-SF12-after: -0.023680 (± 0.050101)\n",
      "SES_after: -0.015821 (± 0.053958)\n",
      "SLEC_after: -0.053564 (± 0.061629)\n",
      "KFSS_M-after_2y: 0.272986 (± 0.048213)\n",
      "KFSS_P-after_2y: -0.030198 (± 0.176686)\n",
      "EDSS-after_2y: 0.418373 (± 0.044445)\n",
      "NRELAP: 0.642013 (± 0.016795)\n",
      "CESEV: 0.562311 (± 0.035818)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "scores_with_std = []\n",
    "\n",
    "# Iterate over each outcome variable in the folds\n",
    "for variable_name in variables: \n",
    "    variable_scores = []\n",
    "    \n",
    "    # Scores for the variable across all folds\n",
    "    for fold_index in range(len(y_test_cv)):\n",
    "        y_test = y_test_cv[fold_index][variables.index(variable_name)] \n",
    "        y_pred = y_pred_cv[fold_index][variables.index(variable_name)] \n",
    "        \n",
    "        # Check if the target variable is numerical or categorical\n",
    "        if y_test.dtype.kind in 'bifc':\n",
    "            score = r2_score(y_test, y_pred)\n",
    "        else:\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "                  \n",
    "        variable_scores.append(score)\n",
    "    \n",
    "    # Average score for the variable across all folds\n",
    "    variable_avg_score = np.mean(variable_scores)\n",
    "    # Standard deviation for the variable across all folds\n",
    "    variable_std_score = np.std(variable_scores)\n",
    "    scores_with_std.append((variable_name, variable_avg_score, variable_std_score))\n",
    "\n",
    "print(\"Scores for each outcome (chain - true values):\")\n",
    "for variable_name, avg_score, std_score in scores_with_std:\n",
    "    print(f\"{variable_name}: {avg_score:.6f} (± {std_score:.6f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
